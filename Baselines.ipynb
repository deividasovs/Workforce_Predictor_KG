{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding baselines to beat with model\n",
    "Used to predict next x months by just repeating observered volume.  \n",
    "Measuring the model's effectiveness.\n",
    "If the model can't beat these it's practically useless\n",
    "\n",
    "https://towardsdatascience.com/how-to-build-a-baseline-model-be6ce42389fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from ipynb.fs.full.training_preprocessing import GetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deividas/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/data/encoders.py:388: UserWarning: scale is below 1e-7 - consider not centering the data or using data with higher variance for numerical stability\n",
      "  warnings.warn(\n",
      "/Users/deividas/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/parsing.py:263: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/Users/deividas/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/parsing.py:263: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel_architecture\u001b[39;00m \u001b[39mimport\u001b[39;00m tft, training, val_dataloader, train_dataloader, validation, training\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_absolute_error\n",
      "File \u001b[0;32m~/Workplace/Workforce_Scheduler_Workspace/demand-forecaster-sam/model_architecture.py:57\u001b[0m\n\u001b[1;32m     53\u001b[0m val_dataloader \u001b[39m=\u001b[39m validation\u001b[39m.\u001b[39mto_dataloader(\n\u001b[1;32m     54\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39mbatch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[39m# create the model\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m tft \u001b[39m=\u001b[39m TemporalFusionTransformer\u001b[39m.\u001b[39;49mfrom_dataset(\n\u001b[1;32m     58\u001b[0m     training,\n\u001b[1;32m     59\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,\n\u001b[1;32m     60\u001b[0m     hidden_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     61\u001b[0m     attention_head_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     62\u001b[0m     dropout\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     63\u001b[0m     hidden_continuous_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     64\u001b[0m     output_size\u001b[39m=\u001b[39;49m[\u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m],\n\u001b[1;32m     65\u001b[0m     \u001b[39m# loss=QuantileLoss(),\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m     loss\u001b[39m=\u001b[39;49mMultiLoss([QuantileLoss(), QuantileLoss(),\n\u001b[1;32m     67\u001b[0m                    QuantileLoss(), QuantileLoss(), QuantileLoss()]),\n\u001b[1;32m     68\u001b[0m     log_interval\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     69\u001b[0m     reduce_on_plateau_patience\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of parameters in network: \u001b[39m\u001b[39m{\u001b[39;00mtft\u001b[39m.\u001b[39msize()\u001b[39m/\u001b[39m\u001b[39m1e3\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:353\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.from_dataset\u001b[0;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdeduce_default_output_parameters(dataset, kwargs, QuantileLoss()))\n\u001b[1;32m    352\u001b[0m \u001b[39m# create class and return\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfrom_dataset(\n\u001b[1;32m    354\u001b[0m     dataset, allowed_encoder_known_variable_names\u001b[39m=\u001b[39;49mallowed_encoder_known_variable_names, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py:1474\u001b[0m, in \u001b[0;36mBaseModelWithCovariates.from_dataset\u001b[0;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[1;32m   1454\u001b[0m new_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m   1455\u001b[0m     static_categoricals\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mstatic_categoricals,\n\u001b[1;32m   1456\u001b[0m     time_varying_categoricals_encoder\u001b[39m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     categorical_groups\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mvariable_groups,\n\u001b[1;32m   1472\u001b[0m )\n\u001b[1;32m   1473\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m-> 1474\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfrom_dataset(dataset, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py:987\u001b[0m, in \u001b[0;36mBaseModel.from_dataset\u001b[0;34m(cls, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39moutput_transformer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    986\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moutput_transformer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtarget_normalizer\n\u001b[0;32m--> 987\u001b[0m net \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    988\u001b[0m net\u001b[39m.\u001b[39mdataset_parameters \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_parameters()\n\u001b[1;32m    989\u001b[0m \u001b[39mif\u001b[39;00m dataset\u001b[39m.\u001b[39mmulti_target:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:140\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.__init__\u001b[0;34m(self, hidden_size, lstm_layers, dropout, output_size, loss, attention_head_size, max_encoder_length, static_categoricals, static_reals, time_varying_categoricals_encoder, time_varying_categoricals_decoder, categorical_groups, time_varying_reals_encoder, time_varying_reals_decoder, x_reals, x_categoricals, hidden_continuous_size, hidden_continuous_sizes, embedding_sizes, embedding_paddings, embedding_labels, learning_rate, log_interval, log_val_interval, log_gradient_flow, reduce_on_plateau_patience, monotone_constaints, share_single_variable_networks, logging_metrics, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m# store loss function separately as it is a module\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(loss, LightningMetric), \u001b[39m\"\u001b[39m\u001b[39mLoss has to be a PyTorch Lightning `Metric`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 140\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(loss\u001b[39m=\u001b[39;49mloss, logging_metrics\u001b[39m=\u001b[39;49mlogging_metrics, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39m# processing inputs\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# embeddings\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_embeddings \u001b[39m=\u001b[39m MultiEmbedding(\n\u001b[1;32m    145\u001b[0m     embedding_sizes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39membedding_sizes,\n\u001b[1;32m    146\u001b[0m     categorical_groups\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mcategorical_groups,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     max_embedding_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mhidden_size,\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py:261\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, log_interval, log_val_interval, learning_rate, log_gradient_flow, loss, logging_metrics, reduce_on_plateau_patience, reduce_on_plateau_reduction, reduce_on_plateau_min_lr, weight_decay, optimizer_params, monotone_constaints, output_transformer, optimizer)\u001b[0m\n\u001b[1;32m    258\u001b[0m frame \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mcurrentframe()\n\u001b[1;32m    259\u001b[0m init_args \u001b[39m=\u001b[39m get_init_args(frame)\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_hyperparameters(\n\u001b[0;32m--> 261\u001b[0m     {name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m init_args\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    264\u001b[0m \u001b[39m# update log interval if not defined\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mlog_val_interval \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from model_architecture import tft, training, val_dataloader, train_dataloader, validation, training\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>rain</th>\n",
       "      <th>temperature</th>\n",
       "      <th>holiday</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>workforce_type_1</th>\n",
       "      <th>workforce_type_2</th>\n",
       "      <th>workforce_type_3</th>\n",
       "      <th>workforce_type_4</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>constant_group</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-17 10:00:00</td>\n",
       "      <td>428.03</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>False</td>\n",
       "      <td>69.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-17 11:00:00</td>\n",
       "      <td>324.78</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>False</td>\n",
       "      <td>69.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-17 12:00:00</td>\n",
       "      <td>279.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>False</td>\n",
       "      <td>69.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-17 13:00:00</td>\n",
       "      <td>1630.59</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>False</td>\n",
       "      <td>69.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-17 14:00:00</td>\n",
       "      <td>1166.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>False</td>\n",
       "      <td>69.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5062</th>\n",
       "      <td>2022-11-30 14:00:00</td>\n",
       "      <td>4779.11</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5062</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5063</th>\n",
       "      <td>2022-11-30 15:00:00</td>\n",
       "      <td>2460.84</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5063</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5064</th>\n",
       "      <td>2022-11-30 16:00:00</td>\n",
       "      <td>2026.30</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5064</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>2022-11-30 17:00:00</td>\n",
       "      <td>2346.13</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5065</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5066</th>\n",
       "      <td>2022-11-30 18:00:00</td>\n",
       "      <td>401.19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5066</td>\n",
       "      <td>group_1</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5067 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  subtotal  transaction_count  rain  temperature  \\\n",
       "0    2021-05-17 10:00:00    428.03               11.0   0.0         12.7   \n",
       "1    2021-05-17 11:00:00    324.78               15.0   0.0         13.4   \n",
       "2    2021-05-17 12:00:00    279.75               12.0   0.0         13.6   \n",
       "3    2021-05-17 13:00:00   1630.59               29.0   0.0         14.1   \n",
       "4    2021-05-17 14:00:00   1166.10               18.0   0.0         15.9   \n",
       "...                  ...       ...                ...   ...          ...   \n",
       "5062 2022-11-30 14:00:00   4779.11               82.0   0.0          0.0   \n",
       "5063 2022-11-30 15:00:00   2460.84               54.0   0.0          0.0   \n",
       "5064 2022-11-30 16:00:00   2026.30               43.0   0.0          0.0   \n",
       "5065 2022-11-30 17:00:00   2346.13               44.0   0.0          0.0   \n",
       "5066 2022-11-30 18:00:00    401.19                6.0   0.0          0.0   \n",
       "\n",
       "      holiday  oil_price  workforce_type_1  workforce_type_2  \\\n",
       "0       False      69.62               1.0               2.0   \n",
       "1       False      69.62               1.0               2.0   \n",
       "2       False      69.62               1.0               2.0   \n",
       "3       False      69.62               1.0               2.0   \n",
       "4       False      69.62               1.0               2.0   \n",
       "...       ...        ...               ...               ...   \n",
       "5062    False      83.45               1.0               4.0   \n",
       "5063    False      83.45               1.0               4.0   \n",
       "5064    False      83.45               1.0               4.0   \n",
       "5065    False      83.45               1.0               4.0   \n",
       "5066    False      83.45               1.0               4.0   \n",
       "\n",
       "      workforce_type_3  workforce_type_4  time_idx constant_group  year  \\\n",
       "0                  3.0               0.0         0        group_1  2021   \n",
       "1                  3.0               1.0         1        group_1  2021   \n",
       "2                  3.0               1.0         2        group_1  2021   \n",
       "3                  3.0               1.0         3        group_1  2021   \n",
       "4                  3.0               1.0         4        group_1  2021   \n",
       "...                ...               ...       ...            ...   ...   \n",
       "5062               5.0               0.0      5062        group_1  2022   \n",
       "5063               5.0               0.0      5063        group_1  2022   \n",
       "5064               5.0               0.0      5064        group_1  2022   \n",
       "5065               5.0               0.0      5065        group_1  2022   \n",
       "5066               5.0               0.0      5066        group_1  2022   \n",
       "\n",
       "      month  day  hour  \n",
       "0         5   17    10  \n",
       "1         5   17    11  \n",
       "2         5   17    12  \n",
       "3         5   17    13  \n",
       "4         5   17    14  \n",
       "...     ...  ...   ...  \n",
       "5062     11   30    14  \n",
       "5063     11   30    15  \n",
       "5064     11   30    16  \n",
       "5065     11   30    17  \n",
       "5066     11   30    18  \n",
       "\n",
       "[5067 rows x 17 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = GetDataset()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m val_dataloader \u001b[39m=\u001b[39m validation\u001b[39m.\u001b[39mto_dataloader(train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39mbatch_size \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m actuals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([y \u001b[39mfor\u001b[39;49;00m x, (y, weight) \u001b[39min\u001b[39;49;00m \u001b[39miter\u001b[39;49m(val_dataloader)])\n\u001b[1;32m     11\u001b[0m baseline_predictions \u001b[39m=\u001b[39m Baseline()\u001b[39m.\u001b[39mpredict(val_dataloader)\n\u001b[1;32m     12\u001b[0m (actuals \u001b[39m-\u001b[39m baseline_predictions)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  \n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 8.698412698412698\n"
     ]
    }
   ],
   "source": [
    "# Given range, see how close the mean of previous 2 weeks and next 2 weeks is to the actual value\n",
    "\n",
    "date_to_predict = pd.to_datetime('2022-10-20 10:00:00')\n",
    "\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Get the transaction_count values from the last week of df\n",
    "prev_week_1 = df[(df['Timestamp'] >= date_to_predict - pd.Timedelta(days=7)) & (df['Timestamp'] < date_to_predict)]['transaction_count']\n",
    "prev_week_2 = df[(df['Timestamp'] >= date_to_predict - pd.Timedelta(days=15)) & (df['Timestamp'] < date_to_predict - pd.Timedelta(days=7))]['transaction_count']\n",
    "\n",
    "next_week_1 = df[(df['Timestamp'] <= date_to_predict + pd.Timedelta(days=14)) & (df['Timestamp'] > date_to_predict + pd.Timedelta(days=7))]['transaction_count']\n",
    "next_week_2 = df[(df['Timestamp'] <= date_to_predict + pd.Timedelta(days=21)) & (df['Timestamp'] > date_to_predict + pd.Timedelta(days=14))]['transaction_count']\n",
    "\n",
    "actual_week = df[(df['Timestamp'] >= date_to_predict) & (df['Timestamp'] < date_to_predict + pd.Timedelta(days=7))]['transaction_count']\n",
    "\n",
    "# For each field in last_2_weeks and next_2_weeks, get the mean between them \n",
    "# and store it in a new dataframe\n",
    "predicted_with_means = []\n",
    "for i in range (len(prev_week_1)):\n",
    "    # Append to df2\n",
    "    predicted_with_means.append((prev_week_1.iloc[i] + prev_week_2.iloc[i] + next_week_1.iloc[i] + next_week_2.iloc[i]) / 4)\n",
    "\n",
    "\n",
    "# Get the mean absolute error between the actual values and the predicted values\n",
    "mae = mean_absolute_error(actual_week, predicted_with_means)\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 13.25, Actual: 11.0\n",
      "Difference: 2.25\n"
     ]
    }
   ],
   "source": [
    "date_to_predict = pd.to_datetime('2022-10-20 10:00:00')\n",
    "\n",
    "prev_date_1 = df[df['Timestamp'] == date_to_predict - pd.Timedelta(weeks=1)]['transaction_count'].values[0]\n",
    "prev_date_2 = df[df['Timestamp'] == date_to_predict - pd.Timedelta(weeks=2)]['transaction_count'].values[0]\n",
    "\n",
    "next_date_1 = df[df['Timestamp'] == date_to_predict + pd.Timedelta(weeks=1)]['transaction_count'].values[0]\n",
    "next_date_2 = df[df['Timestamp'] == date_to_predict + pd.Timedelta(weeks=2)]['transaction_count'].values[0]\n",
    "\n",
    "predicted = (prev_date_1 + prev_date_2 + next_date_1 + next_date_2) / 4\n",
    "\n",
    "actual = df[df['Timestamp'] == date_to_predict]['transaction_count'].values[0]\n",
    "\n",
    "print(f'Predicted: {predicted}, Actual: {actual}')\n",
    "print(f'Difference: {abs(predicted - actual)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate date_to_predict \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
